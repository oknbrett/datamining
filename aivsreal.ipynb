{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77ba287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/codespace/.cache/kagglehub/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images/versions/3\n",
      "Found 100000 files belonging to 2 classes.\n",
      "Found 20000 files belonging to 2 classes.\n",
      "Class names: ['FAKE', 'REAL']\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Download the CIFAKE dataset\n",
    "path = kagglehub.dataset_download(\"birdy654/cifake-real-and-ai-generated-synthetic-images\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Define paths to training and test directories\n",
    "train_dir = os.path.join(path, 'train')\n",
    "test_dir = os.path.join(path, 'test')\n",
    "\n",
    "# Load dataset using TensorFlow's image_dataset_from_directory\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(32, 32),  # CIFAKE images are 32x32\n",
    "    batch_size=32,\n",
    "    label_mode='binary'   # 0 for real, 1 for AI-generated\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    label_mode='binary'\n",
    ")\n",
    "\n",
    "# Verify dataset\n",
    "class_names = train_dataset.class_names\n",
    "print(\"Class names:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38812153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preprocessed and ready!\n"
     ]
    }
   ],
   "source": [
    "# Purpose: Normalize images (0-1 range) and optimize loading speed\n",
    "train_dataset = train_dataset.map(lambda x, y: (x / 255.0, y))  # Normalize pixel values\n",
    "train_dataset = train_dataset.cache().prefetch(tf.data.AUTOTUNE)  # Speed up training\n",
    "\n",
    "test_dataset = test_dataset.map(lambda x, y: (x / 255.0, y))  # Normalize test set\n",
    "test_dataset = test_dataset.cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Dataset preprocessed and ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba1c82ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built and compiled!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Purpose: Define a CNN model to classify AI-generated vs real images\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary output: 0 (REAL) or 1 (FAKE)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Model built and compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbf3e910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 27ms/step - accuracy: 0.8119 - loss: 0.4039 - val_accuracy: 0.8745 - val_loss: 0.2868\n",
      "Epoch 2/5\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 14ms/step - accuracy: 0.9117 - loss: 0.2225 - val_accuracy: 0.9075 - val_loss: 0.2223\n",
      "Epoch 3/5\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 14ms/step - accuracy: 0.9268 - loss: 0.1847 - val_accuracy: 0.9211 - val_loss: 0.1950\n",
      "Epoch 4/5\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 14ms/step - accuracy: 0.9371 - loss: 0.1605 - val_accuracy: 0.9297 - val_loss: 0.1788\n",
      "Epoch 5/5\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 14ms/step - accuracy: 0.9455 - loss: 0.1403 - val_accuracy: 0.9262 - val_loss: 0.1828\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Purpose: Train the model on the dataset to learn AI vs real image patterns\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=5  # Start with 5 epochs, adjust later if needed\n",
    ")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a821784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 11/625\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9279 - loss: 0.1456  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9251 - loss: 0.1837\n",
      "Test Accuracy: 92.62%\n",
      "Test Loss: 0.1828\n"
     ]
    }
   ],
   "source": [
    "# Purpose: Test the model’s accuracy on the unseen test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "799d0fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 5 epochs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, Test Accuracy: 92.18%\n",
      "Training with 10 epochs...\n",
      "Epochs: 10, Test Accuracy: 92.38%\n",
      "Training with 15 epochs...\n",
      "Epochs: 15, Test Accuracy: 92.64%\n",
      "Training with 20 epochs...\n",
      "Epochs: 20, Test Accuracy: 92.88%\n",
      "Best number of epochs: 20 with accuracy: 92.88%\n"
     ]
    }
   ],
   "source": [
    "# Purpose: Test multiple epoch values and find the best accuracy\n",
    "epoch_range = [5, 10, 15, 20]  # Epochs to try\n",
    "results = {}\n",
    "\n",
    "# Rebuild the simpler model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Loop through epochs\n",
    "for epochs in epoch_range:\n",
    "    print(f\"Training with {epochs} epochs...\")\n",
    "    model.fit(train_dataset, validation_data=test_dataset, epochs=epochs, verbose=0)\n",
    "    test_loss, test_accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "    results[epochs] = test_accuracy\n",
    "    print(f\"Epochs: {epochs}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Find best result\n",
    "best_epochs = max(results, key=results.get)\n",
    "print(f\"Best number of epochs: {best_epochs} with accuracy: {results[best_epochs] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f03d8122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (5 epochs): 92.64%\n",
      "Model 2 (15 epochs): 92.66%\n"
     ]
    }
   ],
   "source": [
    "# Purpose: Compare models with fixed randomness\n",
    "tf.random.set_seed(42)  # Fix randomness\n",
    "\n",
    "# Original model (5 epochs)\n",
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model1.fit(train_dataset, epochs=5, verbose=0)\n",
    "loss1, acc1 = model1.evaluate(test_dataset, verbose=0)\n",
    "print(f\"Model 1 (5 epochs): {acc1 * 100:.2f}%\")\n",
    "\n",
    "# Best from grid (15 epochs)\n",
    "model2 = tf.keras.Sequential([  # Same architecture\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model2.fit(train_dataset, epochs=15, verbose=0)\n",
    "loss2, acc2 = model2.evaluate(test_dataset, verbose=0)\n",
    "print(f\"Model 2 (15 epochs): {acc2 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b22e6034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Prediction: AI-generated (Confidence: 92.11%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Rebuild Model 1 with seed for consistency\n",
    "tf.random.set_seed(42)\n",
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model1.fit(train_dataset, epochs=5, verbose=0)\n",
    "\n",
    "# Load and preprocess an image (replace 'your_image.jpg' with your file path)\n",
    "img_path = '/workspaces/datamining/ChatGPT Image Apr 9, 2025, 08_50_11 PM.png'  # Upload an image to your environment\n",
    "img = Image.open(img_path).resize((32, 32))  # Resize to 32x32\n",
    "img_array = np.array(img) / 255.0  # Normalize\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# Predict\n",
    "prediction = model1.predict(img_array)\n",
    "result = \"AI-generated\" if prediction[0][0] > 0.5 else \"Real\"\n",
    "confidence = prediction[0][0] if prediction[0][0] > 0.5 else 1 - prediction[0][0]\n",
    "print(f\"Prediction: {result} (Confidence: {confidence * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ebfee",
   "metadata": {},
   "source": [
    "Below is a real image, photographed by a real person, and is predicted as AI-generated. This goes to show the limitation in the training dataset. The dataset was very out-dated and could not handle variety well. With a better dataset, things might be different. However, my PC wouldn't be able to handle such data. Given a good dataset and a good PC, I believe this could be achieved. This is what already happening with xAI and X (twitter) when Elon Musk sold X to xAI. This gives xAI a huge environment with real-time data every seconds by real people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efab835b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load and preprocess an image (replace 'your_image.jpg' with your file path)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/workspaces/datamining/josh-hild-16ZUFFYQdbo-unsplash.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Upload an image to your environment\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m))  \u001b[38;5;66;03m# Resize to 32x32\u001b[39;00m\n\u001b[1;32m      4\u001b[0m img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m  \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[1;32m      5\u001b[0m img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "# Load and preprocess an image (replace 'your_image.jpg' with your file path)\n",
    "img_path = '/workspaces/datamining/josh-hild-16ZUFFYQdbo-unsplash.jpg'  # Upload an image to your environment\n",
    "img = Image.open(img_path).resize((32, 32))  # Resize to 32x32\n",
    "img_array = np.array(img) / 255.0  # Normalize\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# Predict\n",
    "prediction = model1.predict(img_array)\n",
    "result = \"AI-generated\" if prediction[0][0] > 0.5 else \"Real\"\n",
    "confidence = prediction[0][0] if prediction[0][0] > 0.5 else 1 - prediction[0][0]\n",
    "print(f\"Prediction: {result} (Confidence: {confidence * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db1555",
   "metadata": {},
   "source": [
    "Here I tried to create a website to upload an image and the model will tell you whether or not the picture is AI-generated, when I turned it into a Flask app, I kept hitting errors like ‘SystemExit: 1’ because of port conflicts in Codespace. I couldn’t get the server running smoothly in time, even with help. The model works, but the app part just wouldn’t cooperate..\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d51463a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 2 classes.\n",
      "Starting server on port 58783...\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:58783\n",
      " * Running on http://10.0.13.110:58783\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 692, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/zmq/sugar/socket.py\", line 311, in bind\n",
      "    super().bind(addr)\n",
      "  File \"_zmq.py\", line 917, in zmq.backend.cython._zmq.Socket.bind\n",
      "  File \"_zmq.py\", line 179, in zmq.backend.cython._zmq._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:9002')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "import kagglehub\n",
    "import socket\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load CIFAKE dataset\n",
    "path = kagglehub.dataset_download(\"birdy654/cifake-real-and-ai-generated-synthetic-images\")\n",
    "train_dir = os.path.join(path, 'train')\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    label_mode='binary'\n",
    ").map(lambda x, y: (x / 255.0, y)).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Load Model 1\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_dataset, epochs=5, verbose=0)\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def upload_image():\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['image']\n",
    "        img = Image.open(file.stream).resize((32, 32))\n",
    "        img_array = np.array(img) / 255.0\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        prediction = model.predict(img_array)\n",
    "        result = \"AI-generated\" if prediction[0][0] > 0.5 else \"Real\"\n",
    "        confidence = prediction[0][0] if prediction[0][0] > 0.5 else 1 - prediction[0][0]\n",
    "        return f\"Prediction: {result} (Confidence: {confidence * 100:.2f}%)\"\n",
    "    return '''\n",
    "        <h1>AI vs Real Image Detector</h1>\n",
    "        <form method=\"post\" enctype=\"multipart/form-data\">\n",
    "            <input type=\"file\" name=\"image\">\n",
    "            <input type=\"submit\" value=\"Upload\">\n",
    "        </form>\n",
    "    '''\n",
    "\n",
    "# Find a free port\n",
    "def get_free_port():\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.bind(('', 0))\n",
    "    port = s.getsockname()[1]\n",
    "    s.close()\n",
    "    return port\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    port = get_free_port()\n",
    "    print(f\"Starting server on port {port}...\")\n",
    "    try:\n",
    "        app.run(host='0.0.0.0', port=port, debug=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
